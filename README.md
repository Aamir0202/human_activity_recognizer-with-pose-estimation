This project implements a **real-time system** that integrates **YOLOv8** for object detection and pose estimation with a **pre-trained I3D model** for human action recognition using the **Kinetics-400 dataset**. The system is capable of:

- Detecting human poses in live video streams.
- Classifying actions in real-time based on pose data.
- Overlaying the most likely actions above detected individuals.
- Displaying the top 5 predicted actions in the terminal for detailed insights.

By combining **state-of-the-art AI models**, this system enables **simultaneous object detection, pose estimation, and action classification**, making it applicable in a variety of domains, including:

- **Sports analytics**
- **Security and surveillance**
- **Human-computer interaction**
